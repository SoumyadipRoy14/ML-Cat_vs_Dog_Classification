{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BEYil2OCpcCI"
      },
      "outputs": [],
      "source": [
        "# Dataset - https://www.kaggle.com/datasets/salader/dogs-vs-cats"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "#Dataset size is too high. Instead of exporting, adding the Kaggle API to directly import the data"
      ],
      "metadata": {
        "id": "9ltXgmnE_AjI"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d salader/dogs-vs-cats\n",
        "#Downloading dataset from Kaggle"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Ygyow4lpz7K",
        "outputId": "6d2504cf-fc19-4a55-f9af-ad6dfc1c52db"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Dataset URL: https://www.kaggle.com/datasets/salader/dogs-vs-cats\n",
            "License(s): unknown\n",
            "dogs-vs-cats.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Dataset is downloaded but in zip fotmat.\n",
        "#Extracting the data by inporting zipfile directory"
      ],
      "metadata": {
        "id": "GwR35qgp8JMe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile as zp\n",
        "zip_ref = zp.ZipFile('/content/dogs-vs-cats.zip', 'r')\n",
        "zip_ref.extractall('/content')\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "dRq_DVNNp7T-"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Importing necessary Libraries"
      ],
      "metadata": {
        "id": "_H0npBrt8cKl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import Sequential\n",
        "from keras.layers import Dense,Conv2D,MaxPooling2D,Flatten,BatchNormalization,Dropout"
      ],
      "metadata": {
        "id": "HLjhKoPuqLL1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating training and validation datasets using image_dataset_from_directory\n",
        "train_ds = keras.utils.image_dataset_from_directory(\n",
        "    directory = '/content/train',\n",
        "    labels='inferred',\n",
        "    label_mode = 'int',\n",
        "    batch_size=32,\n",
        "    image_size=(256,256)\n",
        ")\n",
        "\n",
        "validation_ds = keras.utils.image_dataset_from_directory(\n",
        "    directory = '/content/test',\n",
        "    labels='inferred',\n",
        "    label_mode = 'int',\n",
        "    batch_size=32,\n",
        "    image_size=(256,256)\n",
        ")"
      ],
      "metadata": {
        "id": "-f2dkRxXqobD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As there is large size data to train, we have distributed them by Keras Generator named 'image_dataset_from_directory'"
      ],
      "metadata": {
        "id": "3ktmYkGWTW2W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalizing the image pixel data, to get the data size from 0 to 1...by dividing it with 255"
      ],
      "metadata": {
        "id": "QubN7mEI9ahO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize\n",
        "def process(image,label):\n",
        "    image = tf.cast(image/255. ,tf.float32)\n",
        "    return image,label\n",
        "\n",
        "train_ds = train_ds.map(process)\n",
        "validation_ds = validation_ds.map(process)"
      ],
      "metadata": {
        "id": "2H94lUTyr_Rd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training the CNN Model for Classification"
      ],
      "metadata": {
        "id": "FDKMHz84-J2k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create CNN model\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "#First Layer with 32 Filters\n",
        "model.add(Conv2D(32,kernel_size=(3,3),padding='valid',activation='relu',input_shape=(256,256,3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2),strides=2,padding='valid'))\n",
        "\n",
        "#Second Layer with 64 Filters\n",
        "model.add(Conv2D(64,kernel_size=(3,3),padding='valid',activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2),strides=2,padding='valid'))\n",
        "\n",
        "#Third Layer with 128 Filters\n",
        "model.add(Conv2D(128,kernel_size=(3,3),padding='valid',activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2),strides=2,padding='valid'))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(128,activation='relu'))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(64,activation='relu'))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(1,activation='sigmoid'))"
      ],
      "metadata": {
        "id": "_FcGcmkescVi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Displaying the model summary"
      ],
      "metadata": {
        "id": "kPLcV3DUFXRs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "7aJZyq2Ltdno"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compiling the model"
      ],
      "metadata": {
        "id": "B4yW8dadFdmv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "SL-E5k_5tf9N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training the model"
      ],
      "metadata": {
        "id": "G74fimUtFnel"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_ds,epochs=10,validation_data=validation_ds)"
      ],
      "metadata": {
        "id": "HHBFNFHCtzLu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plotting training and validation accuracy"
      ],
      "metadata": {
        "id": "qff0qOqpFv57"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['accuracy'],color='red',label='train')\n",
        "plt.plot(history.history['val_accuracy'],color='blue',label='validation')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GLXWhpapuAuV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plotting training and validation loss"
      ],
      "metadata": {
        "id": "cLSqSLvgF0ph"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'],color='red',label='train')\n",
        "plt.plot(history.history['val_loss'],color='blue',label='validation')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wgG1voHM2rlf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing OpenCV for image processing\n",
        "import cv2"
      ],
      "metadata": {
        "id": "x4qNNsN28GTc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the model_predict function to classify the image\n",
        "# Classifying the new test image\n",
        "def model_predict(img):\n",
        "    img = cv2.resize(img, (256, 256))  # Resize the image to 256x256 pixels\n",
        "    img = img.reshape((1, 256, 256, 3))  # Reshape the image to match model input\n",
        "    prediction = model.predict(img)  # Make prediction using the model\n",
        "    if prediction > 0.5:  # Check if the prediction is more than 0.5 (dog)\n",
        "        print('This is the image of a Dog')\n",
        "    else:  # If the prediction is 0.5 or less (cat)\n",
        "        print('This is the image of a Cat')"
      ],
      "metadata": {
        "id": "bgdFXd7KEzFn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reading another test image\n",
        "sampleimg1 = cv2.imread('ABCD_cat.jpg')\n",
        "model_predict(sampleimg1)"
      ],
      "metadata": {
        "id": "yp0rmmqYHKhZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sampleimg2 = cv2.imread('cat.jpg')\n",
        "model_predict(sampleimg2)"
      ],
      "metadata": {
        "id": "BU3N6vPQ8z_t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sampleimg3 = cv2.imread('Dog.jpeg')\n",
        "model_predict(sampleimg3)"
      ],
      "metadata": {
        "id": "eXn0GHHMQ-pD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8yCKvEXkXG3x"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}